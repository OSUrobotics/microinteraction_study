<launch>
	<arg name="projector_camera_id" default="0"/>
	<arg name="camera" default="projector_cam"/>
	<arg name="ip" default="0.0.0.0"/>
	<arg name="port" default="9999"/>

	<arg name="wall_frame_id" default="ar_marker_0"/>

	<param name="wall_frame_id" value="$(arg wall_frame_id)"/>
	<param name="mouse_capture_name" value="mouse_capture_node"/>

	<!-- params for mouse capture node (launched in run_study.py) -->
	<group ns="mouse_capture_node">
		<param name="frame_id" value="$(arg wall_frame_id)"/>
		<param name="offset_x" value="-0.5"/>
		<param name="offset_y" value="0"/>
	</group>
	<!-- <param name="study_data_dir" value="$(find projector_interface)/study/data"/> -->

	<!-- note:  microinteraction_study need to be in the same place on the remote machine -->
	<machine
		name="tv"
		address="dvalinn.local"
		env-loader="$(find microinteraction_study)/setup.sh"
		user="lazewatd"
	/>

	<!-- services for interacting with VLC -->
	<node name="vlc" type="vlcplayer.py" pkg="vlc" machine="tv" output="screen"/>

	<!-- run devilspie2 to put the various windows on the right screens -->
	<node name="devilspie2" type="run_devilspie2.sh" pkg="microinteraction_study" machine="tv" output="screen"/>

	<!-- rosbridge -->
	<include file="$(find rosbridge_server)/launch/rosbridge_websocket.launch"/>


	<!-- config -->
<!-- 	<include file="$(find projector_interface)/study/launch/setup.launch"/>

	<param name="/screen/border_x" type="double" value="0.35"/>
	<param name="/screen/border_y" type="double" value="0.35"/>
 -->
	<!-- webcam driver  -->
	<include file="$(find simple_webcam)/launch/camera_pipeline+machine.launch">
		<arg name="machine" value="tv"/>
		<arg name="camera_id" value="$(arg projector_camera_id)"/>
		<arg name="info_url" value="file://$(find projector_interface)/study/cfg/camera.yaml"/>
		<arg name="camera" value="$(arg camera)"/>
	</include>

	<!-- wall marker -->
	<node name="ar_track_alvar" pkg="ar_track_alvar" type="individualMarkersNoKinect" respawn="false" output="screen"
		args="12
		      0.08
		      0.2
		      $(arg camera)/image_raw
		      $(arg camera)/camera_info
		      /world" />

	<!-- projection system -->
	<include file="$(find projector_interface)/launch/calibrate_and_circle+machine.launch">
		<arg name="flip" value="false"/>
		<arg name="machine" value="tv"/>
		<arg name="calibrate" value="true"/>
		<arg name="calibration_camera" value="$(arg camera)"/>
		<arg name="window_size" value="1"/>
	</include>

	<!-- projected interface -->
	<node name="projected" pkg="microinteraction_study" type="projected.py" args="$(find microinteraction_study)/interfaces/projected.pkl">
		<param name="start_muted" value="true"/>
	</node>

	<!-- practice_interface -->
	<node name="practice" pkg="microinteraction_study" type="practice.py" args="$(find microinteraction_study)/interfaces/practice.pkl">
		<param name="start_muted" value="true"/>
	</node>

	<!-- set the interface's frame -->
	<node name="$(anon dynparam)" pkg="dynamic_reconfigure" type="dynparam" args="set_from_parameters projected">
		<param name="frame_id" type="string" value="$(arg wall_frame_id)" />
	</node>

	<!-- study sequencer -->
	<!-- <node name="sequencer" pkg="microinteraction_study" type="run_study.py"/> -->

	<!-- glass -->
	<node name="sensor_bridge" type="glassSensorBridge.py" pkg="glass_ros_bridge" args="$(arg ip) $(arg port)"/>
	<node name="start_glass" type="start_glass" pkg="glass_ros_bridge"/>

	<!-- 	fake face detection frame - assume a person is standing (approx 1.0 meters high)
	yaw (4th number) will need to be adjusted since glass' 0 is at magnetic north -->
    <arg name="face_frame_pub" value="face_detection"/>
	<node args="0 0 1.0 0 0 0 world /face_detection 100" name="$(arg face_frame_pub)" pkg="reconfigurable_transform_publisher" type="transform_publisher.py"/>

    <arg name="glass_adjust_pub" value="glass_adjust"/>
	<node args="0 0 0 0 0 0 /face_detection /glass_adjust 100" name="$(arg glass_adjust_pub)" pkg="reconfigurable_transform_publisher" type="transform_publisher.py"/>

    <!-- <node name="adjust_face_detection" type="glass_offset.py" pkg="microinteraction_study" args="$(arg glass_adjust_pub)"/> -->

    <arg name="wall_frame_reconfig_pub" value="$(arg wall_frame_id)_reconfig_pub"/>
	<node name="$(arg wall_frame_reconfig_pub)" pkg="reconfigurable_transform_publisher" type="transform_publisher.py" clear_params="true"/>

    <node name="staticify_marker" pkg="reconfigurable_transform_publisher" type="make_static.py" args="-r $(arg wall_frame_reconfig_pub) -k projector_cam_rgb_optical_frame $(arg wall_frame_id) -w 10"/>

	<node args="0 0 1.0 0 0 0 world /$(arg camera)_link 100" name="camera_tf" pkg="reconfigurable_transform_publisher" type="transform_publisher.py"/>

	<!-- Intersect the pose with the screen plane -->
 	<node name="intersect_plane" pkg="world_intersect" type="intersect_plane.py">
		<remap from="pose" to="/android/pose"/>
		<param name="plane_frame" value="$(arg wall_frame_id)"/>
  </node>

  <node name="splashscreen" type="splashscreen.py" pkg="splashscreen" machine="tv"/>
  <node name="splashscreen_local" type="splashscreen.py" pkg="splashscreen"/>

</launch>
